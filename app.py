import streamlit as st
from langchain.chat_models import ChatOpenAI
from langchain.chains import ConversationChain
from langchain.memory import ConversationBufferMemory

# Titel
st.title("üßÆ Mathe-KI-Agent mit Ged√§chtnis")

# API-Key aus Streamlit Secrets
api_key = st.secrets["OPENAI_API_KEY"]

# Initialisiere GPT-4-Modell √ºber LangChain
llm = ChatOpenAI(
    openai_api_key=api_key,
    model="gpt-4",
    temperature=0.4  # optional: weniger kreativ, mehr sachlich
)

# Ged√§chtnis vorbereiten (f√ºr Session)
memory = ConversationBufferMemory()

# Prompt: GPT soll wie Mathelehrer antworten
conversation = ConversationChain(
    llm=llm,
    memory=memory,
    verbose=False
)
conversation.prompt.template = (
    "Du bist ein geduldiger Mathematik-Coach f√ºr Sch√ºler:innen der Sekundarstufe 1. "
    "Antworte in einfachen Worten, mit Beispielen, und stelle auch R√ºckfragen, wenn n√∂tig.\n\n"
    "Chatverlauf:\n{history}\nSch√ºler: {input}\nCoach:"
)

# Eingabefeld f√ºr SuS
frage = st.text_input("Gib hier deine Mathefrage ein:")

# Verarbeite Frage
if frage:
    with st.spinner("GPT denkt nach..."):
        antwort = conversation.run(frage)
        st.markdown("### üí¨ Antwort:")
        st.write(antwort)

        # Optional: Verlauf anzeigen
        with st.expander("üß† Verlauf (Ged√§chtnis anzeigen)"):
            st.write(memory.buffer)
